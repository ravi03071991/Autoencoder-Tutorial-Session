{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XuFwMRtFvcQl",
    "outputId": "bc16df04-0a23-4a6c-b0a3-119c839d85ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "-tQ4_wsMxmly",
    "outputId": "6ae6909c-7cfd-434d-b0f8-866ee769e1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape is:  (60000, 784)\n",
      "x_test shape is:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(\"x_train shape is: \", x_train.shape)\n",
    "print(\"x_test shape is: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2010
    },
    "colab_type": "code",
    "id": "EMVG2daPx0d7",
    "outputId": "cd20e40c-64b2-4112-e2ac-7ead0818b8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "decoder (Dense)              (None, 784)               50960     \n",
      "=================================================================\n",
      "Total params: 101,200\n",
      "Trainable params: 101,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2452 - val_loss: 0.1630\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1445 - val_loss: 0.1272\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.1187 - val_loss: 0.1087\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.1044 - val_loss: 0.0978\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0953 - val_loss: 0.0907\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0890 - val_loss: 0.0855\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0846 - val_loss: 0.0819\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0815 - val_loss: 0.0795\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0793 - val_loss: 0.0777\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0778 - val_loss: 0.0764\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0768 - val_loss: 0.0756\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0760 - val_loss: 0.0750\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0754 - val_loss: 0.0745\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0750 - val_loss: 0.0741\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0747 - val_loss: 0.0738\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0744 - val_loss: 0.0736\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0742 - val_loss: 0.0735\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0740 - val_loss: 0.0734\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0739 - val_loss: 0.0732\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0738 - val_loss: 0.0731\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0737 - val_loss: 0.0730\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0736 - val_loss: 0.0730\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0735 - val_loss: 0.0729\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.0735 - val_loss: 0.0728\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0734 - val_loss: 0.0729\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0733 - val_loss: 0.0727\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0733 - val_loss: 0.0727\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0732 - val_loss: 0.0727\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.0731 - val_loss: 0.0726\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0731 - val_loss: 0.0725\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0730 - val_loss: 0.0724\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0730 - val_loss: 0.0725\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.0729 - val_loss: 0.0724\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0728 - val_loss: 0.0723\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0728 - val_loss: 0.0723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5569d27fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder dimension\n",
    "encoding_dim = 64  \n",
    "\n",
    "# Input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# encoded - encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu', name = \"encoder\")(input_img)\n",
    "\n",
    "# decoded - lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid', name = \"decoder\")(encoded)\n",
    "\n",
    "# autoencoder - model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# encoder - model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# Placeholder for an encoded (64-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "\n",
    "# Last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "\n",
    "# decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "\n",
    "# Compile  model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Fit the model\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "C_qXvY4NyCpa",
    "outputId": "61e61454-3927-495d-ac61-e57102e75b26"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyUAAADnCAYAAAAAXPm9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55a87bf320>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decoded_imgs - decoded representation of test image\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 5  # Display 4 images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bsoG6lglyK1D"
   },
   "outputs": [],
   "source": [
    "# Transform labels to one-hot encodings\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "id": "eW1LG-3HyTeL",
    "outputId": "c361d65a-aa08-4d7e-d6bc-4fcf57799757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 1.6027 - acc: 0.6474\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4235 - acc: 0.8727\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3413 - acc: 0.9002\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3086 - acc: 0.9113\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2921 - acc: 0.9169\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2802 - acc: 0.9205\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2702 - acc: 0.9231\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2640 - acc: 0.9255\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2570 - acc: 0.9273\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2517 - acc: 0.9286\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.2427 - acc: 0.9316\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2348 - acc: 0.9336\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2236 - acc: 0.9372\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2147 - acc: 0.9386\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.2063 - acc: 0.9413\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1947 - acc: 0.9449\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1858 - acc: 0.9466\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1764 - acc: 0.9490\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1677 - acc: 0.9517\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.1595 - acc: 0.9539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55a8765908>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP code goes here for classification\n",
    "\n",
    "# Get the coder output\n",
    "x = autoencoder.get_layer('encoder').output\n",
    "\n",
    "# Create final dense layer for classification\n",
    "y = Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=autoencoder.inputs, outputs=y)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, Y_train, epochs=20, batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "09qaZYJkyh0N",
    "outputId": "d86ca896-762b-4226-e319-c45ff2480c62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss 0.18703153738938272\n",
      "Test Accuracy 0.9458\n"
     ]
    }
   ],
   "source": [
    "# Evaluate it on test data\n",
    "loss_and_metrics = model.evaluate(x_test, Y_test, verbose=2)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Classification using Autoencoders.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
