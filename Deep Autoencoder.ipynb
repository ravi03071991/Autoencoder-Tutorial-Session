{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C9NUxMaRr4sY",
    "outputId": "3bffa5f8-1966-4e96-91e6-298c672e5298"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "17EFt0hnr84h",
    "outputId": "3ba6cde8-98d3-4157-95c3-6aa321465300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1785
    },
    "colab_type": "code",
    "id": "jieWX1gIr-tX",
    "outputId": "f23cbd08-ea9c-424d-87f0-1300fcc123f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.2353 - val_loss: 0.1626\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1470 - val_loss: 0.1348\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1294 - val_loss: 0.1222\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1201 - val_loss: 0.1152\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1137 - val_loss: 0.1097\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1093 - val_loss: 0.1065\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1065 - val_loss: 0.1048\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1043 - val_loss: 0.1023\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1024 - val_loss: 0.1003\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1005 - val_loss: 0.0990\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0990 - val_loss: 0.0971\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0977 - val_loss: 0.0968\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0966 - val_loss: 0.0952\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0956 - val_loss: 0.0941\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0948 - val_loss: 0.0932\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0938 - val_loss: 0.0927\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0924 - val_loss: 0.0911\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0917 - val_loss: 0.0907\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0912 - val_loss: 0.0901\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0907 - val_loss: 0.0896\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0903 - val_loss: 0.0894\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0899 - val_loss: 0.0889\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0895 - val_loss: 0.0887\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.0892 - val_loss: 0.0883\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0888 - val_loss: 0.0882\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0884 - val_loss: 0.0877\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0882 - val_loss: 0.0874\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0878 - val_loss: 0.0874\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0876 - val_loss: 0.0868\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0873 - val_loss: 0.0865\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0870 - val_loss: 0.0863\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0868 - val_loss: 0.0864\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0866 - val_loss: 0.0858\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0863 - val_loss: 0.0860\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0862 - val_loss: 0.0857\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0860 - val_loss: 0.0852\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0857 - val_loss: 0.0853\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0856 - val_loss: 0.0850\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0853 - val_loss: 0.0847\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0852 - val_loss: 0.0847\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0850 - val_loss: 0.0844\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0849 - val_loss: 0.0845\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0848 - val_loss: 0.0844\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0846 - val_loss: 0.0844\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0845 - val_loss: 0.0844\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0844 - val_loss: 0.0839\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0842 - val_loss: 0.0839\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0841 - val_loss: 0.0835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc16be3bbe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# Encoder architecture\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "# Decoder architecture\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "# autoencoder - model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# train the autoencoder\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "jDQUAUsnsSXg",
    "outputId": "d7d85726-804c-4b13-9a07-e4d67e0adf38"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyUAAADnCAYAAAAAXPm9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc169060f98>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decoded_imgs - decoded representation of test image\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 5  # Display 4 images\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Deep Autoencoder.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
